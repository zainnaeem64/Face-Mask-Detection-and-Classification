# -*- coding: utf-8 -*-
"""Face Mask Detection YOLO_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LV84L_x4FYko47n6SilKJRbCVki7k5Jw

# **IMPORT DEPENDENCIES**
"""

import numpy as np 
import pandas as pd
import os
from bs4 import BeautifulSoup
from PIL import Image
import torchvision
from torchvision import transforms, datasets, models
import torch
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from sklearn.model_selection import train_test_split
import matplotlib.patches as patches
import matplotlib.pyplot as plt
from IPython.display import display, Javascript
from google.colab.output import eval_js
from google.colab.patches import cv2_imshow
from base64 import b64decode, b64encode
import cv2
import PIL
import io
import html
import time
import matplotlib.pyplot as plt
import glob

"""# **CONNECT TO GOOGLE DRIVE**"""

# Connect the Colab notebook to Google Drive
from google.colab import drive
drive.mount('/content/gdrive')

"""# **GET DATA FROM GOOGLE DRIVE**"""

# Commented out IPython magic to ensure Python compatibility.
# Getting the images 
# %cd 
from glob import glob
dataset_dir = "/content/gdrive/MyDrive/mask_detection_project/mask_dataset/"

img_list = glob(dataset_dir+'*.jpg')

print(len(img_list))

"""# **HELPING FUNCTIONS**"""







"""# **CLASS DISTRIBUTION** 

"""

# Checking class division
class_count={'0':0,'1':0,'2':0}

for i in glob(dataset_dir+'*.txt'):
  with open(i) as infile:
    for line in infile:
      if(line[0] in class_count):
        class_count[line[0]]+=1


print("Each class count : " ,class_count)

"""# **PLOTTING THE CLASS DISTRIBUTION**"""

# PLotting the class counts to visualize the divisions 

labels = ['Mask','Incorrect','No mask']
sizes = []

for x, y in class_count.items():
    sizes.append(y)

# Plot

explode = (0.05, 0.05, 0.05) 

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)
ax1.axis('equal')  
plt.show()

"""# **PREPROCESSING**"""

def dataset_creation(image_list): 
    image_tensor=[]
    label_tensor=[]
    for i in glob(dataset_dir+'*.txt'):
      with open(i) as infile:
        lines=infile.readlines()
        axis=lines[0].split(' ')
        label,x,y,w,h=int(axis[0]),float(axis[1]),float(axis[2]),float(axis[3]),float(axis[4])
        image = transforms.functional.crop(Image.open(i[:-4]+'.jpg').convert("RGB"), y,x,h-y,w-x)
        image_tensor.append(image)
        label_tensor.append(torch.tensor(label))

    final_dataset = [[k,l] for k,l in zip(image_tensor, label_tensor)]
    return tuple(final_dataset)   

#dataset=dataset_creation(dataset_dir)



"""# **CREATING TRAINING AND VALIDATION DATA**"""

train_img_list, val_img_list = train_test_split(img_list, test_size=0.1, random_state=42)
#print('TRAINING DATA SIZE : '+str(len(train_img_list)), 'VALIDATION DATA SIZE : '+str(len(val_img_list)))

with open('/content/gdrive/MyDrive/mask_detection_project/data/train.txt', 'w') as f:
  f.write('\n'.join(train_img_list) + '\n')

with open('/content/gdrive/MyDrive/mask_detection_project/data/val.txt', 'w') as f:
  f.write('\n'.join(val_img_list) + '\n')

print("Done")

"""# **CLONE DARKNET YOLO INTO COLAB**"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %cd /content
# clone darknet repo|

!git clone https://github.com/AlexeyAB/darknet
from darknet import *



# Commented out IPython magic to ensure Python compatibility.
# change makefile to have GPU and OPENCV enabled
# %cd darknet
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile
!sed -i 's/LIBSO=0/LIBSO=1/' Makefile

# verify CUDA
!/usr/local/cuda/bin/nvcc --version



# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)


!make

"""# **TRAINING**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet/
!wget https://pjreddie.com/media/files/darknet53.conv.74

cp /content/darknet/backup/detect_mask_best.weights /content/gdrive/MyDrive/mask_detection_project/Backup/

ls

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet/
!./darknet detector train /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                          /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                          darknet53.conv.74\
                          -dont_show -map

imShow('chart.png')
download('chart.png')
/content/darknet/backup/d

# Commented out IPython magic to ensure Python compatibility.
#  %cd /content/darknet/
!./darknet detector map /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                        /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                        /content/gdrive/MyDrive/mask_detection_project/Backup/91_v3_friday_25.weights\

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet/
!./darknet detector train /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                          /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                          /content/gdrive/MyDrive/mask_detection_project/Backup/detect_mask_best.weights\
                          -dont_show -ext_output -map

!./darknet detector map /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                        /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                        /content/darknet/backup

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/darknet/
!./darknet detector train /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                          /content/gdrive/MyDrive/mask_detection_project/MASK/yolov7-tiny.cfg\
                          /content/gdrive/MyDrive/mask_detection_project/Weights/yolov7-tiny.conv.87\
                          -dont_show -ext_output -map

!./darknet detector test /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                         /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                        /content/gdrive/MyDrive/mask_detection_project/Backup/detect_mask_best.weights\
                         /content/gdrive/MyDrive/mask_detection_project/demo/12.jpg\
                         -threshold 0.5,.1,1
#clear_output()
imShow('predictions.jpg')

!./darknet detector demo /content/gdrive/MyDrive/mask_detection_project/MASK/object.data\
                         /content/gdrive/MyDrive/mask_detection_project/MASK/detect_mask.cfg\
                         /content/gdrive/MyDrive/mask_detection_project/Weights/yolov3_mask_last.weights\
                         -dont_show\
                         /content/gdrive/MyDrive/mask_detection_project/demo/190312_32_StreetLife_HD_009_cropped.mp4 -i 0 -out_filename results.avi

download('results.avi')





# start streaming video from webcam
video_stream()
# label for video
label_html = 'Capturing...'
# initialze bounding box to empty
bbox = ''
count = 0 
while True:
    js_reply = video_frame(label_html, bbox)
    if not js_reply:
        break

    # convert JS response to OpenCV Image
    frame = js_to_image(js_reply["img"])

    # create transparent overlay for bounding box
    bbox_array = np.zeros([480,640,4], dtype=np.uint8)

    # call our darknet helper on video frame
    detections, width_ratio, height_ratio = darknet_helper(frame, width, height)

    # loop through detections and draw them on transparent overlay image
    for label, confidence, bbox in detections:
      left, top, right, bottom = bbox2points(bbox)
      left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)
      bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)
      bbox_array = cv2.putText(bbox_array, "{} [{:.2f}]".format(label, float(confidence)),
                        (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        class_colors[label], 2)

    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255
    # convert overlay of bbox into bytes
    bbox_bytes = bbox_to_bytes(bbox_array)
    # update bbox so next frame gets new overlay
    bbox = bbox_bytes

try:
  filename = take_photo('photo.jpg')
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  display(Image(filename))
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))

path_image="/kaggle/input/face-mask-detection/images/"  
def face_cas(img): 
    with open(path_annotations+img[:-4]+".xml") as fd:
        doc=xmltodict.parse(fd.read())
    image=plt.imread(os.path.join(path_image+img))
    fig,ax=plt.subplots(1)
    ax.axis("off")
    fig.set_size_inches(10,5)
    temp=doc["annotation"]["object"]
    if type(temp)==list:
        for i in range(len(temp)):
            ###with_mask
            if temp[i]["name"]=="with_mask":
                x,y,w,h=list(map(int,temp[i]["bndbox"].values()))
                mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor='g',facecolor="none",lw=2,)
                ax.add_patch(mpatch)
                rx, ry = mpatch.get_xy()
                ax.annotate("with_mask", (rx, ry), color='green', weight='bold', fontsize=10, ha='left', va='baseline')
            ###without_mask
            if temp[i]["name"]=="without_mask":
                x,y,w,h=list(map(int,temp[i]["bndbox"].values()))     
                mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor='r',facecolor="none",lw=2,)
                ax.add_patch(mpatch)
                rx, ry = mpatch.get_xy()
                ax.annotate("without_mask", (rx, ry), color='red', weight='bold', fontsize=10, ha='left', va='baseline')
            ###mask_weared_incorrect
            if temp[i]["name"]=="mask_weared_incorrect":
                x,y,w,h=list(map(int,temp[i]["bndbox"].values()))
                mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor='y',facecolor="none",lw=2,)
                ax.add_patch(mpatch)
                rx, ry = mpatch.get_xy()
                ax.annotate("mask_weared_incorrect", (rx, ry), color='yellow', weight='bold', fontsize=10, ha='left', va='baseline')
    else:
        x,y,w,h=list(map(int,temp["bndbox"].values()))
        edgecolor={"with_mask":"g","without_mask":"r","mask_weared_incorrect":"y"}
        mpatch=mpatches.Rectangle((x,y),w-x,h-y,linewidth=1, edgecolor=edgecolor[temp["name"]],facecolor="none",)
    ax.imshow(image)
    ax.add_patch(mpatch)

fun_images = img_names.copy()
for i in range(1,8):
    face_cas(fun_images[i])

